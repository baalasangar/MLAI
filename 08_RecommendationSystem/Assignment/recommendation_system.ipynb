{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommendation_system.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/baalasangar/MLAI/blob/master/08_RecommendationSystem/Assignment/recommendation_system.ipynb",
      "authorship_tag": "ABX9TyOg9SUwtrjRHpqGngiLvA0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baalasangar/MLAI/blob/master/08_RecommendationSystem/Assignment/recommendation_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSBZO8m3BP5i"
      },
      "source": [
        "#!pip install surprise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4b0H68Uwo1R"
      },
      "source": [
        "\r\n",
        "#### 1) Importing Liberaries & reading all data\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EiYh-7wtxk"
      },
      "source": [
        "import pandas as pd \r\n",
        "pd.set_option('display.max_columns', None)\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import statsmodels.api as sm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "#%matplotlib inline\r\n",
        "sns.set(style=\"whitegrid\")\r\n",
        "\r\n",
        "from surprise import Dataset\r\n",
        "from surprise import SVD\r\n",
        "from surprise.model_selection.search import GridSearchCV \r\n",
        "from surprise.reader import Reader\r\n",
        "from surprise.model_selection import train_test_split\r\n",
        "from surprise.model_selection.split import KFold \r\n",
        "import surprise.accuracy as accuracy\r\n",
        "from surprise.model_selection.validation import cross_validate\r\n",
        "import random\r\n",
        "\r\n",
        "from collections import defaultdict\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQtPY-mTw5ub"
      },
      "source": [
        "basepath =  \"/RecommendationSys/\"\r\n",
        "#basepath = \"/content/drive/MyDrive/Colab Notebooks/Greatelearning/RecommendationSys/\"\r\n",
        "\r\n",
        "data_rev1 = pd.read_csv(basepath+\"phone_user_review_file_1.csv\",encoding='latin-1')\r\n",
        "data_rev2 = pd.read_csv(basepath+\"phone_user_review_file_2.csv\",encoding='latin-1')\r\n",
        "data_rev3 = pd.read_csv(basepath+\"phone_user_review_file_3.csv\",encoding='latin-1')\r\n",
        "data_rev4 = pd.read_csv(basepath+\"phone_user_review_file_4.csv\",encoding='latin-1')\r\n",
        "data_rev5 = pd.read_csv(basepath+\"phone_user_review_file_5.csv\",encoding='latin-1')\r\n",
        "data_rev6 = pd.read_csv(basepath+\"phone_user_review_file_6.csv\",encoding='latin-1')\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FamECQZzx8J4"
      },
      "source": [
        "# Check the Details for the data\r\n",
        "data_list = [data_rev1,data_rev2,data_rev3,data_rev4,data_rev5,data_rev6]\r\n",
        "for data_object in data_list:\r\n",
        "  print(data_object.columns)\r\n",
        "  print(data_object.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAR3FUwc0iYJ"
      },
      "source": [
        "##### Merge the provided CSVs into one data-frame.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey1nUuSPx7qS"
      },
      "source": [
        "data = pd.concat(data_list)\r\n",
        "data.reset_index(inplace=True)\r\n",
        "data.drop(columns=[\"index\"],inplace=True)\r\n",
        "data.tail(n=10000)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNGc-wZtBRFT"
      },
      "source": [
        "#### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4nQxk9NBW3j"
      },
      "source": [
        "# Create a copy of the data for analysis\r\n",
        "data_analysis = data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KijhMyWK08rA"
      },
      "source": [
        "##### Check a few observations and shape of the data-frame.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F-uCmoG02GI"
      },
      "source": [
        "print(\"Shape of the data - \",data_analysis.shape)\r\n",
        "print(\"Columns of data - \",data_analysis.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHI5km4k3Z0g"
      },
      "source": [
        "# Random check on data for 5o records\r\n",
        "data_analysis.sample(n=25,random_state=612)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn2Oyj2OvgT8"
      },
      "source": [
        "##### formating the phone url Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UznFNh4rqlN2"
      },
      "source": [
        "# formating the phone url Columns\r\n",
        "\r\n",
        "# Check is all the rows starts with \"cellphones\"\r\n",
        "print(data_analysis['phone_url'].str.startswith('/cellphones/').value_counts() )\r\n",
        "data_analysis['phone_url'] = data_analysis['phone_url'].str.replace('/cellphones/','')\r\n",
        "data_analysis['phone_url'] = data_analysis['phone_url'].str[:-1]\r\n",
        "data_analysis['phone_url'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiacvrQYvjuy"
      },
      "source": [
        "##### Analysis the Column \"author\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSz4FQJyvt1s"
      },
      "source": [
        "#pd.set_option('display.max_rows', None)\r\n",
        "print(\"Not of observation with empty - \",data_analysis[\"author\"].isna().sum())\r\n",
        "print(\"Not of observation with empty % - \",(data_analysis[\"author\"].isna().sum() / data_analysis.shape[0])*100) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R05PxjSG-JmW"
      },
      "source": [
        "Since only 1000000 are request for analysis, removing the observation where author names are empty\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYv9_HTw-ojf"
      },
      "source": [
        "\r\n",
        "data_analysis.dropna(subset=[\"author\"],inplace=True)\r\n",
        "data_analysis.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX-qEPS9CEO7"
      },
      "source": [
        "##### Analysis the Column \"Score and score_max\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNbpqCvp_OsW"
      },
      "source": [
        "##### Analysis the Column \"Score and score_max\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWi9mu2d_aL-"
      },
      "source": [
        "print(\"Not of observation with empty - \",data_analysis[\"score\"].isna().sum())\r\n",
        "print(\"Not of observation with empty % - \",(data_analysis[\"score\"].isna().sum() / data_analysis.shape[0])*100) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ROewgA5_1Xr"
      },
      "source": [
        "Since only 1000000 are request for analysis, removing the observation where score names are empty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4I-W5AXCOnz"
      },
      "source": [
        "data_analysis.dropna(subset=[\"score\"],inplace=True)\r\n",
        "data_analysis.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ReE97_fIrk3"
      },
      "source": [
        "# is there any observation with score greater than max score ?\r\n",
        "data_analysis.query(\"score > score_max\").count().sum()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXWXyWDeJG7L"
      },
      "source": [
        " - is there any observation with score greater than max score ? -NO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNysS8gCB9pP"
      },
      "source": [
        "###### Round off scores to the nearest integers\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zd1ffKWB145"
      },
      "source": [
        "data_analysis[\"score\"] = np.round(data_analysis[\"score\"])\r\n",
        "data_analysis[\"score\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tt_01lQXXHT"
      },
      "source": [
        "# is the scoring is done on same scale  ( 1 -10) ?  \r\n",
        "data_analysis[\"score_max\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gR1RsR_XpGS"
      },
      "source": [
        "- is the scoring is done on same scale  ( 1 -10) ?  - YES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERwdItUzBFgq"
      },
      "source": [
        "##### Dropping irrelevant features & removing duplicate columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXqAKh-HEm7n"
      },
      "source": [
        "# Removing the duplicate rows - when phone_url,author & score are same\r\n",
        "rows_with_duplicate = int(data_analysis.shape[0])\r\n",
        "\r\n",
        "print(\"# of Observations - \",rows_with_duplicate)\r\n",
        "data_analysis.drop_duplicates(subset=['phone_url','author','score'],keep='first',inplace=True)\r\n",
        "\r\n",
        "rows_without_duplicate = int(data_analysis.shape[0])\r\n",
        "print(\"# of Observations after removing duplicate - \",rows_without_duplicate)\r\n",
        "\r\n",
        "print(\"% of rows duplicated rows removed - \" , ((rows_with_duplicate - rows_without_duplicate)/rows_with_duplicate)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OhzCtKsZQYA"
      },
      "source": [
        "- 13% duplicated rows have been removed , it's OK since only 10L rows are to be considered for the analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSmTxDbbEAg"
      },
      "source": [
        "# 'phone_url','author','score' are considered for the analysis on other rows are removed.\r\n",
        "data_analysis = data_analysis[['phone_url','author','score']]\r\n",
        "data_analysis.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8b7DZgIcASD"
      },
      "source": [
        "##### Sampling 1000000 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWu9l3rPcAE1"
      },
      "source": [
        "data_analysis = data_analysis.sample(n=1000000,random_state=612)\r\n",
        "print(\"Check the shape \", data_analysis.shape)\r\n",
        "print(\" missing values \", data_analysis.isna().sum().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBNJ9JT0egc7"
      },
      "source": [
        "### 2) Answer the following questions \r\n",
        "\r\n",
        "1.   Identify the most rated features\r\n",
        "2.   Identify the users with most number of reviews.\r\n",
        "3.   Select the data with products having more than 50 ratings and users who have given more than 50 ratings. Report the shape of the final\r\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeDsVbGhLz3x"
      },
      "source": [
        "##### most rated features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-ODq1bhL80-"
      },
      "source": [
        "data_groupby_phone = data_analysis.groupby(by=\"phone_url\").count()\r\n",
        "data_groupby_phone = data_groupby_phone.sort_values(by=['author'],ascending=False)\r\n",
        "data_groupby_phone[\"author\"].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTbS7w4FLk8K"
      },
      "source": [
        " ##### users with most number of reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4jX6KJsCRp-"
      },
      "source": [
        "data_groupby_author = data_analysis.groupby(by=\"author\").count()\r\n",
        "data_groupby_author = data_groupby_author.sort_values(by='phone_url',ascending=False)\r\n",
        "data_groupby_author['phone_url'].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQyuASzRMgJL"
      },
      "source": [
        "#### Filter Data - product with 50 rating and User gave 50 rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLVNRh1FEDCc"
      },
      "source": [
        "data_groupby_phone = data_groupby_phone.query(\"author > 50\")\r\n",
        "data_groupby_author = data_groupby_author.query(\"phone_url > 50\")\r\n",
        "data_analysis = data_analysis[ data_analysis[\"phone_url\"].isin(data_groupby_phone.index) | data_analysis[\"author\"].isin(data_groupby_author.index)]\r\n",
        "print(data_analysis.shape)\r\n",
        "data_analysis.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMZB2IbcNq7P"
      },
      "source": [
        "- 953463 observation selected further anaysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDZiERtzWGWl"
      },
      "source": [
        "### popularity based model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3NJi1KbO4f0"
      },
      "source": [
        "##### recommend top 5 mobile phones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A0gxXGDrEOL"
      },
      "source": [
        "rating_mean_count =  pd.DataFrame(data_analysis.groupby(by=\"phone_url\")[\"score\"].mean())\r\n",
        "rating_mean_count[\"rating_count\"] =  pd.DataFrame(data_analysis.groupby(by=\"phone_url\")[\"score\"].count())\r\n",
        "\r\n",
        "#Product to be considered only when it has more rating count than 90% of the product\r\n",
        "cutoff = rating_mean_count[\"rating_count\"].quantile(0.9)\r\n",
        "rating_mean_count = rating_mean_count.loc[rating_mean_count['rating_count'] >=cutoff]\r\n",
        "rating_mean_count.sort_values(by=[\"score\",\"rating_count\"],ascending=False).head(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aniE7bc_ECw"
      },
      "source": [
        "### collaborative filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JVA0AYP_dvH"
      },
      "source": [
        "##### Matrix Factorization ( using SVD )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV0Zu_EAu-HO"
      },
      "source": [
        "# reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "# matrix_fact_data = Dataset.load_from_df(data_analysis[['author','phone_url','score']],reader)\r\n",
        "# raw_ratings = matrix_fact_data.raw_ratings\r\n",
        "# random.shuffle(raw_ratings)\r\n",
        "\r\n",
        "# # 90% trainset, 10% testset                                                \r\n",
        "# threshold = int(.9 * len(raw_ratings))                                     \r\n",
        "# trainset_raw_ratings = raw_ratings[:threshold]                             \r\n",
        "# test_raw_ratings = raw_ratings[threshold:]\r\n",
        "# matrix_fact_data.raw_ratings = trainset_raw_ratings\r\n",
        "\r\n",
        "\r\n",
        "# param_grid = {'n_factors':[5,10,15,50],'n_epochs':[10,20]}\r\n",
        "# svd_gs = GridSearchCV(SVD, param_grid, measures=['rmse'],cv=KFold(n_splits=5, random_state=123),n_jobs=5)\r\n",
        "# svd_gs.fit(matrix_fact_data)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cpWMUzNQYaW"
      },
      "source": [
        "# print(\"Score \" , svd_gs.best_score)\r\n",
        "# print(\"Best Param \" , svd_gs.best_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0_DubRrz1bs"
      },
      "source": [
        "# svd_bestmodel = SVD(n_factors =svd_gs.best_params['rmse']['n_factors'],n_epochs = svd_gs.best_params['rmse']['n_epochs'])\r\n",
        "# trainset = matrix_fact_data.build_full_trainset()                                      \r\n",
        "# svd_bestmodel.fit(trainset)   \r\n",
        "\r\n",
        "\r\n",
        "# # now test on the trainset                                                 \r\n",
        "# testset = matrix_fact_data.construct_testset(trainset_raw_ratings)                     \r\n",
        "# predictions = svd_bestmodel.test(testset)                                           \r\n",
        "# print('Accuracy on the trainset:')                                         \r\n",
        "# accuracy.rmse(predictions)                                                 \r\n",
        "                                                                           \r\n",
        "# # now test on the testset                                                  \r\n",
        "# testset = matrix_fact_data.construct_testset(test_raw_ratings)                         \r\n",
        "# predictions = svd_bestmodel.test(testset)                                           \r\n",
        "# print('Accuracy on the testset:')                                          \r\n",
        "# accuracy.rmse(predictions)  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjxIhF2v5NfH"
      },
      "source": [
        "###### Train Model with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14WEUhvohHpI"
      },
      "source": [
        "reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "matrix_fact_data = Dataset.load_from_df(data_analysis[['author','phone_url','score']],reader)\r\n",
        "raw_ratings = matrix_fact_data.raw_ratings\r\n",
        "threshold = int(.9 * len(raw_ratings))                                     \r\n",
        "trainset_raw_ratings = raw_ratings[:threshold]                             \r\n",
        "test_raw_ratings = raw_ratings[threshold:]\r\n",
        "matrix_fact_data.raw_ratings = trainset_raw_ratings\r\n",
        "svd = SVD()\r\n",
        "results = cross_validate(svd,matrix_fact_data,measures=['rmse'],cv=5,return_train_measures =True,n_jobs =-1)\r\n",
        "results\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3AT6my85aTX"
      },
      "source": [
        "###### RMSE - for Train / Validate / Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voaVEs7gJlx4"
      },
      "source": [
        "print(\"Average train RMSE -\", results['train_rmse'].mean())\r\n",
        "print(\"Average Validate RMSE -\", results['test_rmse'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ0PE3GncwiC"
      },
      "source": [
        "trainset = matrix_fact_data.build_full_trainset()\r\n",
        "svd.fit(trainset)\r\n",
        "testset = matrix_fact_data.construct_testset(test_raw_ratings)  \r\n",
        "predict = svd.test(testset)\r\n",
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9zQkJUYA1OJ"
      },
      "source": [
        "print(\"Test RMSE - \",accuracy.rmse(predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVc-6Zz_aCO"
      },
      "source": [
        "###### Top 5 recommendation for test user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6HuNnB2AHZE"
      },
      "source": [
        "def get_top_n(predictions, n=10):\r\n",
        "    # First map the predictions to each user.\r\n",
        "    top_n = defaultdict(list)\r\n",
        "    for uid, iid, true_r, est, _ in predictions:\r\n",
        "        top_n[uid].append((iid, est))\r\n",
        "\r\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\r\n",
        "    for uid, user_ratings in top_n.items():\r\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\r\n",
        "        top_n[uid] = user_ratings[:n]\r\n",
        "\r\n",
        "    return top_n\r\n",
        "top_n = get_top_n(predict, n=5) \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNSGYfyk9Ilp"
      },
      "source": [
        "\r\n",
        "test_user = [\"Amazon Customer\",\"Cliente Amazon\",\"Anonymous\",\"Amazon Kunde\",\"Client d'Amazon\",\"David\",\"Alex\",\"Daniel\",\"Chris\",\"Marco\"]\r\n",
        "for test_customer in test_user:\r\n",
        " print(test_customer,\" - \", [iid for (iid, _) in top_n[test_customer]])  \r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvgNwO8kR_ZK"
      },
      "source": [
        "##### Impute outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeUh8_QTA36o"
      },
      "source": [
        "# print(data_analysis[\"score\"].value_counts())\r\n",
        "# data_analysis[\"score\"].value_counts(normalize=True)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKpjlX5aSjCK"
      },
      "source": [
        " - Rating count for (0,1,3) are less than 1% which can be assigned with 2 rating.\r\n",
        " - Rating count of ( 5,6) are less than 1% which can be assigned to 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuFpxle5TrRM"
      },
      "source": [
        "# #data_analysis[\"score_imp\"] = np.where(data_analysis[\"score\"].isin([0,1,3]),2, (data_analysis[\"score\"].isin([5,7]),6,data_analysis[\"score\"]))\r\n",
        "# #data_analysis.head()\r\n",
        "\r\n",
        "# data_analysis[\"score_imp\"]  = np.where(data_analysis[\"score\"].isin([0,1,3]),2, data_analysis[\"score\"])\r\n",
        "# data_analysis[\"score_imp\"] = np.where(data_analysis[\"score_imp\"].isin([5,7]),6,data_analysis[\"score_imp\"])\r\n",
        "# data_analysis[\"score_imp\"].value_counts(normalize=True)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERI-uoy1Z4QG"
      },
      "source": [
        "# reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "# matrix_fact_data = Dataset.load_from_df(data_analysis[['author','phone_url','score_imp']],reader)\r\n",
        "# raw_ratings = matrix_fact_data.raw_ratings\r\n",
        "# threshold = int(.9 * len(raw_ratings))                                     \r\n",
        "# trainset_raw_ratings = raw_ratings[:threshold]                             \r\n",
        "# test_raw_ratings = raw_ratings[threshold:]\r\n",
        "# matrix_fact_data.raw_ratings = trainset_raw_ratings\r\n",
        "# svd = SVD()\r\n",
        "# results = cross_validate(svd,matrix_fact_data,measures=['rmse'],cv=5,return_train_measures =True,n_jobs =-1)\r\n",
        "# print(\"Model results\", results)\r\n",
        "# print(\"Average train RMSE -\", results['train_rmse'].mean())\r\n",
        "# print(\"Average Validate RMSE -\", results['test_rmse'].mean())\r\n",
        "\r\n",
        "# trainset = matrix_fact_data.build_full_trainset()\r\n",
        "# svd.fit(trainset)\r\n",
        "# testset = matrix_fact_data.construct_testset(test_raw_ratings)  \r\n",
        "# predict = svd.test(testset)\r\n",
        "# print(\"Test RMSE - \",accuracy.rmse(predict))\r\n",
        "# predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaEiZypENBoQ"
      },
      "source": [
        "##### User-user collabrative filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOwBd4SJdpys"
      },
      "source": [
        "data_analysis.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qohQ-AsqNLZd"
      },
      "source": [
        "from surprise import KNNWithMeans\r\n",
        "\r\n",
        "\r\n",
        "reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "user_user_data = Dataset.load_from_df(data_analysis[['author','phone_url','score']].sample(random_state=612,n=10000),reader)\r\n",
        "\r\n",
        "trainset, testset = train_test_split(user_user_data, test_size=.25,random_state=123)\r\n",
        "\r\n",
        "trainset.ur\r\n",
        "\r\n",
        "algo = KNNWithMeans(k=50, sim_options={'name': 'cosine', 'user_based': True})\r\n",
        "algo.fit(trainset)\r\n",
        "\r\n",
        "test_pred = algo.test(testset)\r\n",
        "accuracy.rmse(test_pred, verbose=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfxFikGjf88x"
      },
      "source": [
        "test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjvM2v3-f8sU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}