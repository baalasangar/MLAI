{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommendation_system.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "https://github.com/baalasangar/MLAI/blob/master/08_RecommendationSystem/Assignment/recommendation_system.ipynb",
      "authorship_tag": "ABX9TyNIDDUx7RvMi9qmZz6Ct1rG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baalasangar/MLAI/blob/master/08_RecommendationSystem/Assignment/recommendation_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSBZO8m3BP5i"
      },
      "source": [
        "#!pip install surprise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4b0H68Uwo1R"
      },
      "source": [
        "\r\n",
        "#### 1) Importing Liberaries & reading all data\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EiYh-7wtxk"
      },
      "source": [
        "import pandas as pd \r\n",
        "pd.set_option('display.max_columns', None)\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import statsmodels.api as sm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "#%matplotlib inline\r\n",
        "sns.set(style=\"whitegrid\")\r\n",
        "\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "\r\n",
        "from surprise import Dataset\r\n",
        "from surprise import SVD\r\n",
        "from surprise.model_selection.search import GridSearchCV \r\n",
        "from surprise.reader import Reader\r\n",
        "from surprise.model_selection import train_test_split\r\n",
        "from surprise.model_selection.split import KFold \r\n",
        "import surprise.accuracy as accuracy\r\n",
        "from surprise.model_selection.validation import cross_validate\r\n",
        "import random\r\n",
        "from surprise import KNNWithMeans\r\n",
        "\r\n",
        "\r\n",
        "from collections import defaultdict\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQtPY-mTw5ub"
      },
      "source": [
        "basepath =  \"/RecommendationSys/\"\r\n",
        "#basepath = \"/content/drive/MyDrive/Colab Notebooks/Greatelearning/RecommendationSys/\"\r\n",
        "\r\n",
        "data_rev1 = pd.read_csv(basepath+\"phone_user_review_file_1.csv\",encoding='latin-1')\r\n",
        "data_rev2 = pd.read_csv(basepath+\"phone_user_review_file_2.csv\",encoding='latin-1')\r\n",
        "data_rev3 = pd.read_csv(basepath+\"phone_user_review_file_3.csv\",encoding='latin-1')\r\n",
        "data_rev4 = pd.read_csv(basepath+\"phone_user_review_file_4.csv\",encoding='latin-1')\r\n",
        "data_rev5 = pd.read_csv(basepath+\"phone_user_review_file_5.csv\",encoding='latin-1')\r\n",
        "data_rev6 = pd.read_csv(basepath+\"phone_user_review_file_6.csv\",encoding='latin-1')\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FamECQZzx8J4"
      },
      "source": [
        "# Check the Details for the data\r\n",
        "data_list = [data_rev1,data_rev2,data_rev3,data_rev4,data_rev5,data_rev6]\r\n",
        "for data_object in data_list:\r\n",
        "  print(data_object.columns)\r\n",
        "  print(data_object.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAR3FUwc0iYJ"
      },
      "source": [
        "##### Merge the provided CSVs into one data-frame.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey1nUuSPx7qS"
      },
      "source": [
        "data = pd.concat(data_list)\r\n",
        "data.reset_index(inplace=True)\r\n",
        "data.drop(columns=[\"index\"],inplace=True)\r\n",
        "data.tail(n=10000)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNGc-wZtBRFT"
      },
      "source": [
        "#### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4nQxk9NBW3j"
      },
      "source": [
        "# Create a copy of the data for analysis\r\n",
        "data_analysis = data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KijhMyWK08rA"
      },
      "source": [
        "##### Check a few observations and shape of the data-frame.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F-uCmoG02GI"
      },
      "source": [
        "print(\"Shape of the data - \",data_analysis.shape)\r\n",
        "print(\"Columns of data - \",data_analysis.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHI5km4k3Z0g"
      },
      "source": [
        "# Random check on data for 5o records\r\n",
        "data_analysis.sample(n=25,random_state=612)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn2Oyj2OvgT8"
      },
      "source": [
        "##### formating the phone url Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UznFNh4rqlN2"
      },
      "source": [
        "# formating the phone url Columns\r\n",
        "\r\n",
        "# Check is all the rows starts with \"cellphones\"\r\n",
        "print(data_analysis['phone_url'].str.startswith('/cellphones/').value_counts() )\r\n",
        "data_analysis['phone_url'] = data_analysis['phone_url'].str.replace('/cellphones/','')\r\n",
        "data_analysis['phone_url'] = data_analysis['phone_url'].str[:-1]\r\n",
        "data_analysis['phone_url'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiacvrQYvjuy"
      },
      "source": [
        "##### Analysis the Column \"author\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSz4FQJyvt1s"
      },
      "source": [
        "#pd.set_option('display.max_rows', None)\r\n",
        "print(\"Not of observation with empty - \",data_analysis[\"author\"].isna().sum())\r\n",
        "print(\"Not of observation with empty % - \",(data_analysis[\"author\"].isna().sum() / data_analysis.shape[0])*100) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R05PxjSG-JmW"
      },
      "source": [
        "Since only 1000000 are request for analysis, removing the observation where author names are empty\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYv9_HTw-ojf"
      },
      "source": [
        "\r\n",
        "data_analysis.dropna(subset=[\"author\"],inplace=True)\r\n",
        "data_analysis.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX-qEPS9CEO7"
      },
      "source": [
        "##### Analysis the Column \"Score and score_max\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNbpqCvp_OsW"
      },
      "source": [
        "##### Analysis the Column \"Score and score_max\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWi9mu2d_aL-"
      },
      "source": [
        "print(\"Not of observation with empty - \",data_analysis[\"score\"].isna().sum())\r\n",
        "print(\"Not of observation with empty % - \",(data_analysis[\"score\"].isna().sum() / data_analysis.shape[0])*100) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ROewgA5_1Xr"
      },
      "source": [
        "Since only 1000000 are request for analysis, removing the observation where score names are empty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4I-W5AXCOnz"
      },
      "source": [
        "data_analysis.dropna(subset=[\"score\"],inplace=True)\r\n",
        "data_analysis.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ReE97_fIrk3"
      },
      "source": [
        "# is there any observation with score greater than max score ?\r\n",
        "data_analysis.query(\"score > score_max\").count().sum()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXWXyWDeJG7L"
      },
      "source": [
        " - is there any observation with score greater than max score ? -NO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNysS8gCB9pP"
      },
      "source": [
        "###### Round off scores to the nearest integers\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zd1ffKWB145"
      },
      "source": [
        "data_analysis[\"score\"] = np.round(data_analysis[\"score\"])\r\n",
        "data_analysis[\"score\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tt_01lQXXHT"
      },
      "source": [
        "# is the scoring is done on same scale  ( 1 -10) ?  \r\n",
        "data_analysis[\"score_max\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gR1RsR_XpGS"
      },
      "source": [
        "- is the scoring is done on same scale  ( 1 -10) ?  - YES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERwdItUzBFgq"
      },
      "source": [
        "##### Dropping irrelevant features & removing duplicate columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXqAKh-HEm7n"
      },
      "source": [
        "# Removing the duplicate rows - when phone_url,author & score are same\r\n",
        "rows_with_duplicate = int(data_analysis.shape[0])\r\n",
        "\r\n",
        "print(\"# of Observations - \",rows_with_duplicate)\r\n",
        "data_analysis.drop_duplicates(subset=['phone_url','author','score'],keep='first',inplace=True)\r\n",
        "\r\n",
        "rows_without_duplicate = int(data_analysis.shape[0])\r\n",
        "print(\"# of Observations after removing duplicate - \",rows_without_duplicate)\r\n",
        "\r\n",
        "print(\"% of rows duplicated rows removed - \" , ((rows_with_duplicate - rows_without_duplicate)/rows_with_duplicate)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OhzCtKsZQYA"
      },
      "source": [
        "- 13% duplicated rows have been removed , it's OK since only 10L rows are to be considered for the analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSmTxDbbEAg"
      },
      "source": [
        "# 'phone_url','author','score' are considered for the analysis on other rows are removed.\r\n",
        "data_analysis = data_analysis[['phone_url','author','score']]\r\n",
        "data_analysis.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8b7DZgIcASD"
      },
      "source": [
        "##### Sampling 1000000 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWu9l3rPcAE1"
      },
      "source": [
        "data_analysis = data_analysis.sample(n=1000000,random_state=612)\r\n",
        "print(\"Check the shape \", data_analysis.shape)\r\n",
        "print(\" missing values \", data_analysis.isna().sum().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBNJ9JT0egc7"
      },
      "source": [
        "### 2) Answer the following questions \r\n",
        "\r\n",
        "1.   Identify the most rated features\r\n",
        "2.   Identify the users with most number of reviews.\r\n",
        "3.   Select the data with products having more than 50 ratings and users who have given more than 50 ratings. Report the shape of the final\r\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeDsVbGhLz3x"
      },
      "source": [
        "##### most rated features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-ODq1bhL80-"
      },
      "source": [
        "data_groupby_phone = data_analysis.groupby(by=\"phone_url\").count()\r\n",
        "data_groupby_phone = data_groupby_phone.sort_values(by=['author'],ascending=False)\r\n",
        "data_groupby_phone[\"author\"].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTbS7w4FLk8K"
      },
      "source": [
        " ##### users with most number of reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4jX6KJsCRp-"
      },
      "source": [
        "data_groupby_author = data_analysis.groupby(by=\"author\").count()\r\n",
        "data_groupby_author = data_groupby_author.sort_values(by='phone_url',ascending=False)\r\n",
        "data_groupby_author['phone_url'].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQyuASzRMgJL"
      },
      "source": [
        "#### Filter Data - product with 50 rating and User gave 50 rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLVNRh1FEDCc"
      },
      "source": [
        "data_groupby_phone = data_groupby_phone.query(\"author > 50\")\r\n",
        "data_groupby_author = data_groupby_author.query(\"phone_url > 50\")\r\n",
        "data_analysis = data_analysis[ data_analysis[\"phone_url\"].isin(data_groupby_phone.index) | data_analysis[\"author\"].isin(data_groupby_author.index)]\r\n",
        "print(\"Data Size selected for Model Building-- \",data_analysis.shape)\r\n",
        "print(\"Columns Selected -- \",data_analysis.columns)\r\n",
        "data_analysis.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p468cugzy5Ag"
      },
      "source": [
        "#### User & Product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtsDZxxJzA19"
      },
      "source": [
        "print(\"Unique products - \", data_analysis['phone_url'].nunique())\r\n",
        "print(\"No of USers  - \", data_analysis['author'].nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDZiERtzWGWl"
      },
      "source": [
        "### **popularity based model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QthVFh6JqJOE"
      },
      "source": [
        "rating_mean_count =  pd.DataFrame(data_analysis.groupby(by=\"phone_url\")[\"score\"].mean())\r\n",
        "rating_mean_count[\"rating_count\"] =  pd.DataFrame(data_analysis.groupby(by=\"phone_url\")[\"score\"].count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK0QqbH6r6G8"
      },
      "source": [
        "##### Caculating Weighted Score "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUh909kRr-sd"
      },
      "source": [
        "W = ((R*V) + (C*M)) / ( V+M )\r\n",
        " - R = Average score for a product\r\n",
        " - V = total number of counts recived for product\r\n",
        " - M = min votes required to be listed ( 90 % quantile )\r\n",
        " - C = Average vote across the whole product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A0gxXGDrEOL"
      },
      "source": [
        "R = rating_mean_count[\"score\"]\r\n",
        "V = rating_mean_count[\"rating_count\"]\r\n",
        "M = rating_mean_count[\"rating_count\"].quantile(0.9)\r\n",
        "C = rating_mean_count[\"score\"].mean() #Product to be considered only when it has more rating count than 90% of the product\r\n",
        "rating_mean_count[\"weigted_score\"]  = ( (R*V)+ (C*M) / ( V+M ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmMbGYh-vGY1"
      },
      "source": [
        "# minmaxscale = MinMaxScaler()\r\n",
        "# rating_mean_count[\"score_nor\"] = minmaxscale.fit_transform(rating_mean_count[[\"score\"]])\r\n",
        "# rating_mean_count[\"rating_count_nor\"] = minmaxscale.fit_transform(rating_mean_count[[\"rating_count\"]])\r\n",
        "# rating_mean_count[\"weigted_score_nor\"] = minmaxscale.fit_transform(rating_mean_count[[\"weigted_score\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s14SSi7ay9-q"
      },
      "source": [
        "plt.figure(figsize=(12,6))\r\n",
        "vis_data = rating_mean_count.sort_values(by=[\"weigted_score\",\"rating_count\",\"score\"],ascending=False)\r\n",
        "vis_data.reset_index(inplace=True)\r\n",
        "sns.barplot(data=vis_data.head(10) ,y=\"phone_url\",x=\"weigted_score\",orient=\"h\")\r\n",
        "plt.xlabel(\"Weighted Score\")\r\n",
        "plt.ylabel(\"Phone id\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1bZC5ILwf6l"
      },
      "source": [
        "def popularity_recommendation(fileter_col_list,top_n):\r\n",
        "  top_n_item = []\r\n",
        "  return rating_mean_count.sort_values(by=fileter_col_list,ascending=False).index[:top_n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVdZjVcb19Cb"
      },
      "source": [
        "##### Top 5 recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVRtxhuDzj8W"
      },
      "source": [
        "popularity_recommendation([\"weigted_score\",\"rating_count\",\"score\"],5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aniE7bc_ECw"
      },
      "source": [
        "### **collaborative filtering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "129ZnOZVNKj4"
      },
      "source": [
        "def get_top_n(predictions, n=10):\r\n",
        "    # First map the predictions to each user.\r\n",
        "    top_n = defaultdict(list)\r\n",
        "    for uid, iid, true_r, est, details in predictions:\r\n",
        "        if details['was_impossible'] == False:\r\n",
        "            top_n[uid].append((iid, est))\r\n",
        "        \r\n",
        "        \r\n",
        "\r\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\r\n",
        "    for uid, user_ratings in top_n.items():\r\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\r\n",
        "        top_n[uid] = user_ratings[:n]\r\n",
        "\r\n",
        "    return top_n\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvgNwO8kR_ZK"
      },
      "source": [
        "##### Impute outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeUh8_QTA36o"
      },
      "source": [
        "print(data_analysis[\"score\"].value_counts())\r\n",
        "data_analysis[\"score\"].value_counts(normalize=True)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKpjlX5aSjCK"
      },
      "source": [
        " - Rating count for (0,1,3) are less than 1% which can be assigned with 2 rating.\r\n",
        " - Rating count of ( 5,6) are less than 1% which can be assigned to 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuFpxle5TrRM"
      },
      "source": [
        "data_analysis[\"score_imp\"]  = np.where(data_analysis[\"score\"].isin([0,1,3]),2, data_analysis[\"score\"])\r\n",
        "data_analysis[\"score_imp\"] = np.where(data_analysis[\"score_imp\"].isin([5,7]),6,data_analysis[\"score_imp\"])\r\n",
        "data_analysis[\"score_imp\"].value_counts(normalize=True)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaEiZypENBoQ"
      },
      "source": [
        "##### User-user collabrative filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-MenLnSTDe0"
      },
      "source": [
        "###### Train Model with Cross Validation - Without treating outlier (Score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qohQ-AsqNLZd"
      },
      "source": [
        "# reducing the data size to 10K considering limitation computation resources\r\n",
        "data_analysis_CF =  data_analysis[['author','phone_url','score']].sample(random_state=612,n=5000)\r\n",
        "\r\n",
        "reader = Reader(rating_scale=(0, 5))\r\n",
        "user_base_data = Dataset.load_from_df(data_analysis_CF,reader)\r\n",
        "param_grid = {'k': [10,15,20,25,30,35,40,45,50],\r\n",
        "              'bsl_options': {'method': ['als', 'sgd'],\r\n",
        "                              'reg': [1, 2]},\r\n",
        "              'sim_options': {'name': ['pearson_baseline', 'cosine'],\r\n",
        "                              'user_based': [True]}              }\r\n",
        "kmean_gs_user_base = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=KFold(n_splits=3,random_state=123),return_train_measures = True) \r\n",
        "kmean_gs_user_base.fit(user_base_data)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2YrKZpBTOq1"
      },
      "source": [
        "Model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2EvIe2_Nz2m"
      },
      "source": [
        "print(\"Best Score\" , kmean_gs_user_base.best_score['rmse'])\r\n",
        "print(\"best hyperparameter\", kmean_gs_user_base.best_params['rmse'])\r\n",
        "results_df = pd.DataFrame.from_dict(kmean_gs_user_base.cv_results)\r\n",
        "results_df[[\"mean_train_rmse\",\"std_train_rmse\",\"mean_test_rmse\",\"std_test_time\"]].sort_values(by=[\"mean_test_rmse\",\"mean_train_rmse\"])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPrL7ufOXC_1"
      },
      "source": [
        "###### Train Model with Cross Validation - With treating outlier (Score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYHxzPknXMNj"
      },
      "source": [
        "# reducing the data size to 10K considering limitation computation resources\r\n",
        "data_analysis_CF =  data_analysis[['author','phone_url','score_imp']].sample(random_state=612,n=5000)\r\n",
        "\r\n",
        "reader = Reader(rating_scale=(0, 5))\r\n",
        "user_base_data = Dataset.load_from_df(data_analysis_CF,reader)\r\n",
        "param_grid = {'k': [10,15,20,25,30,35,40,45,50],\r\n",
        "              'bsl_options': {'method': ['als', 'sgd'],\r\n",
        "                              'reg': [1, 2]},\r\n",
        "              'sim_options': {'name': ['pearson_baseline', 'cosine'],\r\n",
        "                              'user_based': [True]}              }\r\n",
        "kmean_gs_user_base_v1 = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=KFold(n_splits=3,random_state=123),return_train_measures = True) \r\n",
        "kmean_gs_user_base_v1.fit(user_base_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y1FOT5PXTg4"
      },
      "source": [
        "print(\"Best Score\" , kmean_gs_user_base_v1.best_score['rmse'])\r\n",
        "print(\"best hyperparameter\", kmean_gs_user_base_v1.best_params['rmse'])\r\n",
        "results_df = pd.DataFrame.from_dict(kmean_gs_user_base_v1.cv_results)\r\n",
        "results_df[[\"mean_train_rmse\",\"std_train_rmse\",\"mean_test_rmse\",\"std_test_time\"]].sort_values(by=[\"mean_test_rmse\",\"mean_train_rmse\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66336N-Oa_3M"
      },
      "source": [
        "Observation :\r\n",
        "No Major difference on the model performance when capping the score value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKtwSYkVhV_F"
      },
      "source": [
        "##### predicting with best Model & Top 5 recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brQlwfraXnUy"
      },
      "source": [
        "data_analysis_CF =  data_analysis[['author','phone_url','score']].sample(random_state=612,n=100)\r\n",
        "reader = Reader(rating_scale=(0, 5))\r\n",
        "user_base_data = Dataset.load_from_df(data_analysis_CF,reader)\r\n",
        "trainset = user_base_data.build_full_trainset()\r\n",
        "testset = trainset.build_anti_testset(fill=np.nan)\r\n",
        "best_userbase = kmean_gs_user_base.best_estimator['rmse']\r\n",
        "best_userbase.fit(trainset)\r\n",
        "userbase_prediction = best_userbase.test(testset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEZnzg8E3PkW"
      },
      "source": [
        "userbase_model_pred = pd.DataFrame([[i.uid, i.iid, i.est,i.details['was_impossible']] for i in userbase_prediction], columns=['user_id', 'movie_id', 'score',\"was_impossible\"])\r\n",
        "userbase_model_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2bDfJNy8AN_"
      },
      "source": [
        "test_users = userbase_model_pred.sample(n=10,random_state=123)\r\n",
        "def user_base_recommendation(user_list,n=5):\r\n",
        "  recommendation = dict();\r\n",
        "  for user_id in user_list:\r\n",
        "    movie_list = userbase_model_pred[userbase_model_pred.user_id == user_id].sort_values(by=[\"score\"],ascending=False).head(n=n)[\"movie_id\"]\r\n",
        "    recommendation[user_id] = list(movie_list)\r\n",
        "  return recommendation\r\n",
        "\r\n",
        "user_base_recommendation(test_users[\"user_id\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjvM2v3-f8sU"
      },
      "source": [
        "results_df = pd.DataFrame.from_dict(gs.cv_results)\r\n",
        "\r\n",
        "print(\"Best Score\" , kmean_gs_user_base.best_score['rmse'])\r\n",
        "print(\"best hyperparameter\", kmean_gs_user_base.best_params['rmse'])\r\n",
        "best_kmean = KNNWithMeans(k=kmean_gs.best_params['rmse']['k'],sim_options = kmean_gs.best_params['rmse']['sim_options'])\r\n",
        "best_kmean.fit(trainset)\r\n",
        "test_pred = algo.test(testset)\r\n",
        "print(\"Test Set - RMSE\")\r\n",
        "accuracy.rmse(test_pred, verbose=True)\r\n",
        "\r\n",
        "top_n = get_top_n(test_pred, n=5) \r\n",
        "test_user = [\"Amazon Customer\",\"Cliente Amazon\",\"Anonymous\",\"Amazon Kunde\",\"Client d'Amazon\",\"David\",\"Alex\",\"Daniel\",\"Chris\",\"Marco\"]\r\n",
        "for test_customer in test_user:\r\n",
        " print(test_customer,\" - \", [iid for (iid, _) in top_n[test_customer]])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lU3A-9bZvEr"
      },
      "source": [
        "###### Using the Score Imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRNavzfLPHVH"
      },
      "source": [
        "reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "\r\n",
        "user_user_sample_data = data_analysis[['author','phone_url','score_imp']].sample(random_state=612,n=10000)\r\n",
        "\r\n",
        "\r\n",
        "user_user_data = Dataset.load_from_df(user_user_sample_data,reader)\r\n",
        "trainset, testset = train_test_split(user_user_data, test_size=.3,random_state=123)\r\n",
        "\r\n",
        "param_grid = {'k': [10,15,20,25,30,35,40,45,50],\r\n",
        "              'sim_options': {'name': ['pearson_baseline', 'cosine'],\r\n",
        "                              'user_based': [True]}              }\r\n",
        "kmean_gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=5) \r\n",
        "kmean_gs.fit(user_user_data)\r\n",
        "\r\n",
        "print(\"Best Score\" , kmean_gs.best_score['rmse'])\r\n",
        "print(\"best hyperparameter\", kmean_gs.best_params['rmse'])\r\n",
        "# best_kmean = KNNWithMeans(k=kmean_gs.best_params['rmse']['k'],sim_options = kmean_gs.best_params['rmse']['sim_options'])\r\n",
        "# best_kmean.fit(trainset)\r\n",
        "# test_pred = algo.test(testset)\r\n",
        "# print(\"Test Set - RMSE\")\r\n",
        "# accuracy.rmse(test_pred, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQnP2k75Qf9e"
      },
      "source": [
        "best_kmean = KNNWithMeans(k=kmean_gs.best_params['rmse']['k'],sim_options = kmean_gs.best_params['rmse']['sim_options'])\r\n",
        "best_kmean.fit(trainset)\r\n",
        "test_pred = algo.test(testset)\r\n",
        "print(\"Test Set - RMSE\")\r\n",
        "accuracy.rmse(test_pred, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3cUQmFSQl2m"
      },
      "source": [
        "top_n = get_top_n(test_pred, n=5) \r\n",
        "test_user = [\"Amazon Customer\",\"Cliente Amazon\",\"Anonymous\",\"Amazon Kunde\",\"Client d'Amazon\",\"David\",\"Alex\",\"Daniel\",\"Chris\",\"Marco\"]\r\n",
        "for test_customer in test_user:\r\n",
        " print(test_customer,\" - \", [iid for (iid, _) in top_n[test_customer]])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxAY_FIaYzHv"
      },
      "source": [
        "#### Item Based Collaboration model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NduLetxqYyEQ"
      },
      "source": [
        "reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "\r\n",
        "user_user_sample_data = data_analysis[['author','phone_url','score']].sample(random_state=612,n=10000)\r\n",
        "\r\n",
        "\r\n",
        "user_user_data = Dataset.load_from_df(user_user_sample_data,reader)\r\n",
        "trainset, testset = train_test_split(user_user_data, test_size=.3,random_state=123)\r\n",
        "\r\n",
        "param_grid = {'k': [10,15,20,25,30,35,40,45,50],\r\n",
        "              'sim_options': {'name': ['pearson_baseline', 'cosine'],\r\n",
        "                              'user_based': [False]}              }\r\n",
        "kmean_gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=5) \r\n",
        "kmean_gs.fit(user_user_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEdVuLEiZBGd"
      },
      "source": [
        "print(\"Best Score\" , kmean_gs.best_score['rmse'])\r\n",
        "print(\"best hyperparameter\", kmean_gs.best_params['rmse'])\r\n",
        "best_kmean = KNNWithMeans(k=kmean_gs.best_params['rmse']['k'],sim_options = kmean_gs.best_params['rmse']['sim_options'])\r\n",
        "best_kmean.fit(trainset)\r\n",
        "test_pred = algo.test(testset)\r\n",
        "print(\"Test Set - RMSE\")\r\n",
        "accuracy.rmse(test_pred, verbose=True)\r\n",
        "\r\n",
        "top_n = get_top_n(test_pred, n=5) \r\n",
        "test_user = [\"Amazon Customer\",\"Cliente Amazon\",\"Anonymous\",\"Amazon Kunde\",\"Client d'Amazon\",\"David\",\"Alex\",\"Daniel\",\"Chris\",\"Marco\"]\r\n",
        "for test_customer in test_user:\r\n",
        " print(test_customer,\" - \", [iid for (iid, _) in top_n[test_customer]]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB5oYY5mZX4E"
      },
      "source": [
        "##### Using the Score Imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6o3rC2sZD7a"
      },
      "source": [
        "reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "\r\n",
        "user_user_sample_data = data_analysis[['author','phone_url','score_imp']].sample(random_state=612,n=10000)\r\n",
        "\r\n",
        "\r\n",
        "user_user_data = Dataset.load_from_df(user_user_sample_data,reader)\r\n",
        "trainset, testset = train_test_split(user_user_data, test_size=.3,random_state=123)\r\n",
        "\r\n",
        "param_grid = {'k': [10,15,20,25,30,35,40,45,50],\r\n",
        "              'sim_options': {'name': ['pearson_baseline', 'cosine'],\r\n",
        "                              'user_based': [False]}              }\r\n",
        "kmean_gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=5) \r\n",
        "kmean_gs.fit(user_user_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_i2whLvZP1C"
      },
      "source": [
        "print(\"Best Score\" , kmean_gs.best_score['rmse'])\r\n",
        "print(\"best hyperparameter\", kmean_gs.best_params['rmse'])\r\n",
        "\r\n",
        "best_kmean = KNNWithMeans(k=kmean_gs.best_params['rmse']['k'],sim_options = kmean_gs.best_params['rmse']['sim_options'])\r\n",
        "best_kmean.fit(trainset)\r\n",
        "test_pred = algo.test(testset)\r\n",
        "print(\"Test Set - RMSE\")\r\n",
        "accuracy.rmse(test_pred, verbose=True)\r\n",
        "\r\n",
        "top_n = get_top_n(test_pred, n=5) \r\n",
        "test_user = [\"Amazon Customer\",\"Cliente Amazon\",\"Anonymous\",\"Amazon Kunde\",\"Client d'Amazon\",\"David\",\"Alex\",\"Daniel\",\"Chris\",\"Marco\"]\r\n",
        "for test_customer in test_user:\r\n",
        " print(test_customer,\" - \", [iid for (iid, _) in top_n[test_customer]])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JVA0AYP_dvH"
      },
      "source": [
        "#### Matrix Factorization ( using SVD )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV0Zu_EAu-HO"
      },
      "source": [
        "# reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "# matrix_fact_data = Dataset.load_from_df(data_analysis[['author','phone_url','score']],reader)\r\n",
        "# raw_ratings = matrix_fact_data.raw_ratings\r\n",
        "# random.shuffle(raw_ratings)\r\n",
        "\r\n",
        "# # 90% trainset, 10% testset                                                \r\n",
        "# threshold = int(.9 * len(raw_ratings))                                     \r\n",
        "# trainset_raw_ratings = raw_ratings[:threshold]                             \r\n",
        "# test_raw_ratings = raw_ratings[threshold:]\r\n",
        "# matrix_fact_data.raw_ratings = trainset_raw_ratings\r\n",
        "\r\n",
        "\r\n",
        "# param_grid = {'n_factors':[5,10,15,50],'n_epochs':[10,20]}\r\n",
        "# svd_gs = GridSearchCV(SVD, param_grid, measures=['rmse'],cv=KFold(n_splits=5, random_state=123),n_jobs=5)\r\n",
        "# svd_gs.fit(matrix_fact_data)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cpWMUzNQYaW"
      },
      "source": [
        "# print(\"Score \" , svd_gs.best_score)\r\n",
        "# print(\"Best Param \" , svd_gs.best_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0_DubRrz1bs"
      },
      "source": [
        "# svd_bestmodel = SVD(n_factors =svd_gs.best_params['rmse']['n_factors'],n_epochs = svd_gs.best_params['rmse']['n_epochs'])\r\n",
        "# trainset = matrix_fact_data.build_full_trainset()                                      \r\n",
        "# svd_bestmodel.fit(trainset)   \r\n",
        "\r\n",
        "\r\n",
        "# # now test on the trainset                                                 \r\n",
        "# testset = matrix_fact_data.construct_testset(trainset_raw_ratings)                     \r\n",
        "# predictions = svd_bestmodel.test(testset)                                           \r\n",
        "# print('Accuracy on the trainset:')                                         \r\n",
        "# accuracy.rmse(predictions)                                                 \r\n",
        "                                                                           \r\n",
        "# # now test on the testset                                                  \r\n",
        "# testset = matrix_fact_data.construct_testset(test_raw_ratings)                         \r\n",
        "# predictions = svd_bestmodel.test(testset)                                           \r\n",
        "# print('Accuracy on the testset:')                                          \r\n",
        "# accuracy.rmse(predictions)  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjxIhF2v5NfH"
      },
      "source": [
        "###### Train Model with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14WEUhvohHpI"
      },
      "source": [
        "reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "matrix_fact_data = Dataset.load_from_df(data_analysis[['author','phone_url','score']],reader)\r\n",
        "raw_ratings = matrix_fact_data.raw_ratings\r\n",
        "threshold = int(.9 * len(raw_ratings))                                     \r\n",
        "trainset_raw_ratings = raw_ratings[:threshold]                             \r\n",
        "test_raw_ratings = raw_ratings[threshold:]\r\n",
        "matrix_fact_data.raw_ratings = trainset_raw_ratings\r\n",
        "svd = SVD()\r\n",
        "results = cross_validate(svd,matrix_fact_data,measures=['rmse'],cv=5,return_train_measures =True,n_jobs =-1)\r\n",
        "results\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3AT6my85aTX"
      },
      "source": [
        "###### RMSE - for Train / Validate / Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voaVEs7gJlx4"
      },
      "source": [
        "print(\"Average train RMSE -\", results['train_rmse'].mean())\r\n",
        "print(\"Average Validate RMSE -\", results['test_rmse'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ0PE3GncwiC"
      },
      "source": [
        "trainset = matrix_fact_data.build_full_trainset()\r\n",
        "svd.fit(trainset)\r\n",
        "testset = matrix_fact_data.construct_testset(test_raw_ratings)  \r\n",
        "predict = svd.test(testset)\r\n",
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9zQkJUYA1OJ"
      },
      "source": [
        "print(\"Test RMSE - \",accuracy.rmse(predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVc-6Zz_aCO"
      },
      "source": [
        "###### Top 5 recommendation for test user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcGAezxwcfv1"
      },
      "source": [
        "top_n = get_top_n(predict, n=5) \r\n",
        "test_user = [\"Amazon Customer\",\"Cliente Amazon\",\"Anonymous\",\"Amazon Kunde\",\"Client d'Amazon\",\"David\",\"Alex\",\"Daniel\",\"Chris\",\"Marco\"]\r\n",
        "for test_customer in test_user:\r\n",
        " print(test_customer,\" - \", [iid for (iid, _) in top_n[test_customer]])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMdCT9e3G3U1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDnMC4SkG3RV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neU4MEJJG3L8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfRL45mwG3I0"
      },
      "source": [
        "reader = Reader(rating_scale=(0, 5),line_format='user item rating')\r\n",
        "df = data_analysis[['author','phone_url','score']].sample(random_state=612,n=10)\r\n",
        "data1 = Dataset.load_from_df(df,reader)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZWpXKQpHsdh"
      },
      "source": [
        "trainset = data1.build_full_trainset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJn-HRF9H7iW"
      },
      "source": [
        "trainset.build_anti_testset()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}